#!/bin/bash
## queue/PBS settings
#PBS -l nodes=4:m32g:ppn=8
# batch queue: nodes=4:m32g:ppn=8
# largemem/sandy queue: nodes=1:m128g:ppn=16
#PBS -l walltime=48:00:00
# merge standard error and output stream
#PBS -j oe
#PBS -o $PBS_JOBNAME.$PBS_JOBID.out
# send email if abort (nbae)
#PBS -M aerler@atmosp.physics.utoronto.ca
#PBS -m ae
# job name
#PBS -N gpl_cesmavg_all
###PBS -W depend=afterok:$PBS_JOBID
## submit to queue (NB: this has to be the last PBS line!)
# batch (default), debug, largemem, sandy
#PBS -q batch

# load modules (we need to load the netcdf module in order to use it in Python)
echo
module purge
module load intel/13.1.1 gcc/4.8.1 hdf5/187-v18-serial-intel netcdf/4.1.3_hdf5_serial-intel gnu-parallel/20130422  
module load python/2.7.3 gdal/1.9.2 extras/64_6.4 ncl/6.2.0 gsl/1.13-intel udunits/2.1.11 nco/4.3.2-intel
module load Xlibraries/X11-64 ImageMagick/6.6.7
module list
echo

#shopt -s extglob

# default settings
JOBNAME=${PBS_JOBNAME:-'test'}
WORKDIR=${PBS_O_WORKDIR:-"${PWD}"}
CMDFILE=${CMDFILE:-"${WORKDIR}/cmdfile.${JOBNAME}"}
LOGFILE=${LOGFILE:-"${WORKDIR}/logfile.${JOBNAME}"}
rm -f "${CMDFILE}" "${LOGFILE}" # clean...
THREADS=${THREADS:-4} # GNU Parallel threads
# N.B.: some operations require significant amounts of memory, so that 8 threads is too much

#SRCR='/reserved1/p/peltier/marcdo/FromHpss' # Marc's folder on reserved (default)
#SRCR='/scratch/p/peltier/marcdo/archive/' # Marc's folder on scratch
export CCA=${CAA:-"/reserved1/p/peltier/aerler//CESM/archive/"} # my CESM archive folder as source; used in several scripts

export PYTHON_EGG_CACHE="${WORKDIR}" # not sure why this is necessary

# just for tests
TEST=${TEST:-'FALSE'} # CVDP run script expects FALSE; use TEST=DRYRUN to only generate command file
#RUNS='seaice-3r-hf/'
#PERIODS='5' # averaging periods
# historical runs and projections
ENSEMBLE=${ENSEMBLE:-'ens20trcn1x1/ ensrcp85cn1x1/ ensrcp85cn1x1d/ grand-ensemble/'}
[[ "$ENSEMBLE" == 'NONE' ]] && ENSEMBLE=''
RUNS=${RUNS:-'h[abc]b20trcn1x1/ tb20trcn1x1/ h[abct]brcp85cn1x1/ h[abct]brcp85cn1x1d/ seaice-[35]r-hf/ seaice-5r-hfd/'}
[[ "$RUNS" == 'NONE' ]] && RUNS=''
PERIODS=${PERIODS:-'5 10 15'} # averaging periods
# cesm_average settings
CVDP=${CVDP:-'FALSE'} # Climate Variability Diagnostics Package (set to CVDP)
REFCLM=${REFCLM:-'NONE'} # climatology that is used to remove annual cycle in CVDP" HISTORICAL, PERIOD 
DIAG=${DIAG:-'FALSE'} # Climatology Diagnostics Package (set to DIAG)
CONCAT=${CONCAT:-'FALSE'} # concatenate monthly files (set to CONCAT)
AVERAGE=${AVERAGE:-'FALSE'} # compute climatologies (set to AVERAGE)
OVERWRITE=${OVERWRITE:-'FALSE'} # recompute or not
FILETYPES=${FILETYPES:-'atm lnd ice'} # file types to process

# feedback
cd "${WORKDIR}"
echo ''
echo 'Processing CESM experiments:'
echo ''
ls -d $ENSEMBLE
ls -d $RUNS
echo ''
echo "Computing AMWG Diagnostics: ${DIAG}"
echo "Concatenate Output: ${CONCAT}"
if [[ "${CONCAT}" == 'CONCAT' ]] || [[ "${AVERAGE}" == 'AVERAGE' ]]; then echo "File Types: ${FILETYPES}"; fi
echo "Average Output: ${AVERAGE}"
if [[ "${AVERAGE}" == 'AVERAGE' ]]; then echo "Averaging Periods: ${PERIODS}"; fi
echo "Computing CVDP: ${CVDP}"
echo "Overwriting Files: ${OVERWRITE}"
echo

## function to generate GNU Parallel commands for a given run
function RUNCMDS {
    # translate arguments
    local RUN=$1 # name of the run (folder)
    local MODE=$2 # whether individual run or ensemble
    local FILETYPES=$3 # list of file types 
    local PERIODS=$4 # list of periods
    # set up folders
    RUN=${RUN%/} # remove trailing slash, if any
    RUNDIR="${WORKDIR}/${RUN}/" # extract highest order folder name as run name
    AVGDIR="${RUNDIR}/cesmavg/" # subfolder for averages
    echo "   ***   Preparing $RUN   ***   "
    echo "   ($RUNDIR)" 
    cd "${RUNDIR}"

    # determine period and other meta data from name
    if [[ "$RUN" == *20tr* ]]; then SPRD='1979'; EPRD='1993'; HREF='OBS'; 
    elif [[ "$RUN" == *rcp* ]]; then 
      if [[ "$RUN" == htbrcp* ]]; then HREF="tb20tr${RUN#*rcp??}" # special case
      else HREF="${RUN%rcp*}20tr${RUN#*rcp??}"; fi # guess name of historical simulation
      if [[ "$RUN" == *d ]]; then SPRD='2085'; EPRD='2099'; HREF=${HREF%d}; 
      else SPRD='2045'; EPRD='2059'; fi
    elif [[ "$RUN" == seaice-5r-hfd ]]; then SPRD='2085'; EPRD='2099'; HREF='tb20trcn1x1'
    elif [[ "$RUN" == seaice-5r-hf ]]; then SPRD='2045'; EPRD='2059'; HREF='tb20trcn1x1'
    elif [[ "$RUN" == seaice-*-hf ]]; then SPRD='2045'; EPRD='2059'; HREF='tb20trcn1x1'
    elif [[ "$RUN" == grand-ensemble ]]; then SPRD='1000'; EPRD='1014'; HREF='' # using '0' seems to cause problems
    else echo "ERROR: No settings found for experiment '$RUN' - aborting!"; exit 1     
    fi # $RUN settings
    EEPRD=$(( $EPRD +1 )) # different convention in climatology file
    H_CLIM_FILE="$CCA/ens20trcn1x1/cesmavg/cesmatm_clim_1979-1994.nc" # historical climatology for CVDP
    # reference/control runs for ensemble and external climatologies for CVDP (for each period)
    # N.B.: the external climatology is for an option taht was added to CVDP, but is currently not used  
    case $SPRD in # ensemble control
        1979) CREF='tb20trcn1x1'; P_CLIM_FILE="$CCA/ens20trcn1x1/cesmavg/cesmatm_clim_${SPRD}-${EEPRD}.nc";;
        2045) CREF='htbrcp85cn1x1'; P_CLIM_FILE="$CCA/ensrcp85cn1x1/cesmavg/cesmatm_clim_${SPRD}-${EEPRD}.nc";;
        2085) CREF='htbrcp85cn1x1d'; P_CLIM_FILE="$CCA/ensrcp85cn1x1d/cesmavg/cesmatm_clim_${SPRD}-${EEPRD}.nc";;
        1000) CREF=''; P_CLIM_FILE="";; # not needed
    esac
    HPRD='1979'; CPRD=$SPRD # begin of reference periods: historical and current/control
    if [[ "$RUN" == "$CREF" ]]; then CREF=''; CPRD=''; fi # special case: can't compare to itself
    # save meta info in script for later reference
    echo "RUN='${RUN}'; SPRD='${SPRD}'; EPRD='${EPRD}'; HREF='${HREF}'; HPRD='${RPRD}'; CREF='${CREF}'; CPRD='${CPRD}'" > exp_info.sh     
    #source exp_info.sh # defines RUN, SPRD, EPRD, HREF, HPRD, CREF, and CPRD for each run
    # N.B.: To process any experiment, simply add a meta data/settings file named 'exp_info.sh' to to the
    #       experiment's root folder, where the above parameters are defined (as shell environment variables); 
    #       the script is then sourced at this point, and parameters are set.
    NPRD=$(( 1 + $EPRD - $SPRD )) # length of period; end year is inclusive
    # calculate periods
    PRDS='' # clear variable
    for PRD in $PERIODS; do
      if [ $PRD -le $NPRD ]; then PRDS="${PRDS} ${SPRD}-$(( $SPRD + $PRD ))"; fi
    done # loop over start dates and periods

    
    ## Climatology Diagnostics Package (AMWG)
    if [[ "${DIAG}" == 'DIAG' ]] && [[ "${MODE}" == 'RUN' ]]
      then
        mkdir -p "$RUNDIR/diag/" # make sure destination folder exists
        ln -sf "${MODEL_ROOT}/WRF Tools/Scripts/GPC/run_amwg_diag.csh" # link AMWG script (CSH)
        # current/control reference
        if [[ -n "$HREF" ]]; then 
          if [[ "$HREF" == 'OBS' ]]; then DIAGTAR="$RUNDIR/diag/$RUN-obs.tar"
          else DIAGTAR="$RUNDIR/diag/$RUN-$HREF.tar"; fi
          if [ ! -f "$DIAGTAR" ] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
            echo "   Running AMWG Diagnostics: $DIAGTAR"
            echo "cd $RUNDIR; csh -ef run_amwg_diag.csh $RUN $SPRD $NPRD $HREF $HPRD &> $RUNDIR/diag_hist.log" >> "${CMDFILE}.diag"
          else
            echo "   Skipping AMWG Diagnostics: $DIAGTAR"
          fi # if actually running
        fi # $HREF
        # current/control reference
        if [[ -n "$CREF" ]]; then 
          if [[ "$CREF" == 'OBS' ]]; then DIAGTAR="$RUNDIR/diag/$RUN-obs.tar"
          else DIAGTAR="$RUNDIR/diag/$RUN-$CREF.tar"; fi
          if [ ! -f "$DIAGTAR" ] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
            echo "   Running AMWG Diagnostics: $DIAGTAR"
            echo "cd $RUNDIR; csh -ef run_amwg_diag.csh $RUN $SPRD $NPRD $CREF $CPRD &> $RUNDIR/diag_ctrl.log" >> "${CMDFILE}.diag"
          else
            echo "   Skipping AMWG Diagnostics: $DIAGTAR"
          fi # if actually running
        fi # $CREF
    fi # $DIAG 
       
       
    # loop iver file types
    for FILETYPE in $FILETYPES
      do
        
        ## concatenate history files
        if [[ "${CONCAT}" == 'CONCAT' ]] && [[ "${MODE}" == 'RUN' ]]
          then
            mkdir -p "${AVGDIR}" # make sure destination folder exists
            ## assemble time-series
            case $FILETYPE in
              atm) FILES="${RUNDIR}/${FILETYPE}/hist/${RUN}.cam2.h0";; 
              lnd) FILES="${RUNDIR}/${FILETYPE}/hist/${RUN}.clm2.h0";; 
              ice) FILES="${RUNDIR}/${FILETYPE}/hist/${RUN}.cice.h";; 
            esac
            # list of proper years
            FILELIST=''
            for Y in $( seq $SPRD $EPRD ); do
              FILELIST="${FILELIST} ${FILES}.${Y}-??.nc"; done
            # NCO command
            NCOARGS="--netcdf4 --deflate 1" # use NetCDF4 compression
            NCOOUT="${AVGDIR}/cesm${FILETYPE}_monthly.nc"
            if [[ ! -e "${NCOOUT}" ]] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
              echo "   Concatenating: ${NCOOUT}"
              echo "cd ${RUNDIR}; ncrcat $NCOARGS --output ${NCOOUT} --overwrite ${FILELIST} &> ${NCOOUT%.nc}.log" >> "${CMDFILE}.concat"
            else
              echo "   Skipping: ${NCOOUT}"
            fi # if already file exits
        fi # $CONCAT

        ## compute climatologies (from monthly averages)
        if [[ "${AVERAGE}" == 'AVERAGE' ]] && [[ "${MODE}" == 'RUN' ]]
          then
            mkdir -p "${AVGDIR}" # make sure destination folder exists
            ln -sf "${MODEL_ROOT}/WRF Tools/Python/wrfavg/cesm_average.py" # link averaging script
            # loop over averaging periods
            for PERIOD in $PRDS
              do
                ## compute averaged climatologies
                # launch python script, save output in log file
                PYAVGOUT="${AVGDIR}/cesm${FILETYPE}_clim_${PERIOD}.nc"
                if [[ ! -f "$PYAVGOUT" ]] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
                  echo "   Averaging: ${PYAVGOUT}"
                  echo "cd ${RUNDIR}; export PYAVG_FILETYPE=${FILETYPE}; python -u cesm_average.py ${PERIOD} &> ${PYAVGOUT%.nc}.log" >> "${CMDFILE}.average"
                else
                  echo "   Skipping: ${PYAVGOUT}"
                fi # if already file exits
            done # for $PERIODS
        fi # $AVERAGE

    done # for $FILETYPES


    ## climate variability diagnostics (CVDP)
    if [[ "${CVDP}" == 'CVDP' ]] # also works for ensemble mode
      then
        mkdir -p "$RUNDIR/cvdp/" # make sure destination folder exists
        ln -sf "${MODEL_ROOT}/WRF Tools/NCL/CVDP/run_cvdp.sh" # link CVDP driver script
        #if [ -f "$RUNDIR/cvdp.log" ]; then CVDPOUT=$( grep -c 'The NCL driver script completed successfully' "$RUNDIR/cvdp.log" )
        #else CVDPOUT=0; fi # always run CVDP, if no logs are present
        if [ ! -f "$RUNDIR/cvdp/cvdp.tar" ] || [[ "$OVERWRITE" == 'OVERWRITE' ]]; then
          echo "   Running CVDP"
          rm -rf "$RUNDIR/cvdp/" 
          export TEST # TEST=NAMELISTS_ONLY only generates namelists
          if [[ "$REFCLM" == 'NONE' ]]; then CLIMO='' # don't use external climatology
          elif [[ "$REFCLM" == 'HISTORICAL' ]]; then CLIMO="$H_CLIM_FILE"
          elif [[ "$REFCLM" == 'PERIOD' ]]; then CLIMO="$P_CLIM_FILE"
          fi # currently no other options
          echo "cd $RUNDIR; bash -e run_cvdp.sh $RUN $SPRD $EPRD $CLIMO &> $RUNDIR/cvdp.log" >> "${CMDFILE}.cvdp" 
        else
          echo "   Skipping CVDP"
        fi # if actually running
    fi # $CVDP
} # fct RUNCMDS

## generate command file for GNU Parallel
# root directory
cd "${WORKDIR}"
touch "${CMDFILE}.diag" "${CMDFILE}.concat" "${CMDFILE}.average" "${CMDFILE}.cvdp"
# loop over ensemble
if [[ -n "$ENSEMBLE" ]]
  then
    for ENS in $( ls -d $ENSEMBLE )
      do
        echo
        RUNCMDS "$ENS" 'ENSEMBLE' # generate commands for individual runs
    done # for $ENSEMBLE
  cd "${WORKDIR}"
  echo  
fi # if $ENSEMBLE
# loop over runs
if [[ -n "$RUNS" ]]
  then
    for RUN in $( ls -d $RUNS )
      do
        echo
        RUNCMDS "$RUN" 'RUN' "$FILETYPES" "$PERIODS" # generate commands for individual runs
    done # for $RUNS
  cd "${WORKDIR}"
  echo 
fi # if $RUNS

# assemble command file (so that not all processes are accessing the same files at once)
cat "${CMDFILE}.diag" "${CMDFILE}.concat" "${CMDFILE}.average" "${CMDFILE}.cvdp" > "${CMDFILE}"
rm "${CMDFILE}.diag" "${CMDFILE}.concat" "${CMDFILE}.average" "${CMDFILE}.cvdp"

## execute GNU Parallel commands
echo # print command
echo "parallel --sshloginfile \"$PBS_NODEFILE\" --workdir \"$PWD\" "
echo "         --env PYTHON_EGG_CACHE   = $PYTHON_EGG_CACHE"
echo "         --env CCA                = $CCA             "
echo "         --env TEST               = $TEST            "
echo "        -j ${THREADS} --joblog \"${LOGFILE}\" < \"${CMDFILE}\" "
if [[ "$TEST" != 'DRYRUN' ]]
  then
    #parallel -j $THREADS --joblog "${LOGFILE}" < "${CMDFILE}" # only for single-node execution
    parallel --sshloginfile "$PBS_NODEFILE" --workdir "$PWD" \
              --env PYTHON_EGG_CACHE \
              --env CCA \
              --env TEST \
             -j ${THREADS} --joblog "${LOGFILE}" < "${CMDFILE}"
    ERR=$? # capture exit code
else
    ERR=1
fi # if DRYRUN
echo

# clean up
echo
if [[ 0 == ${ERR} ]]
  then
    echo '   ***   All Jobs Completed Successfully!!!   ***   '
    rm "${CMDFILE}" "${LOGFILE}"
elif [[ "$TEST" == 'DRYRUN' ]]
  then
    echo '   ===   This was a dry-run --- inspect the command file   ===   '
    echo "   '${CMDFILE}'"
else
    echo "  >>>   ERRORS DETECTED - EXIT CODE ${ERR}   <<<   " 
    echo "Inspect command and log files:"
    echo "   '${CMDFILE}'"
    echo "   '${LOGFILE}'"
    echo
    cat "${LOGFILE}"
fi # if $ERR
echo

# exit with gnuparallel exit code
exit ${ERR}
