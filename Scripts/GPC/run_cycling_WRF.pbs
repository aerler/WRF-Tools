#!/bin/bash
# MOAB/Torque submission script for SciNet GPC

## queue/PBS settings
#PBS -l nodes=16:ppn=8
#PBS -l walltime=6:00:00
# std and error output
#PBS -j oe
#PBS -o $PBS_JOBNAME.$PBS_JOBID.out
# send email if abort (nbae)
#PBS -M aerler@atmosp.physics.utoronto.ca
#PBS -m a
# job name
#PBS -N cycling_WRF
# job dependency
#PBS -W depend:afterok:cycling_WPS
# N.B.: this ${PBS_JOBNAME%_WRF}_WPS does not work
## submit to queue (NB: this has to be the last PBS line!)
# batch (default), debug, largemem
#PBS -q batch

set -e # abort if anything goes wrong
# check if $NEXTSTEP is set, and exit, if not
if [[ -z "${NEXTSTEP}" ]]; then
  echo 'Environment variable $NEXTSTEP not set - aborting!'
  exit 1
fi
CURRENTSTEP="${NEXTSTEP}" # $NEXTSTEP will be overwritten
export NEXTSTEP
export CURRENTSTEP


## job settings
export JOBNAME="${PBS_JOBNAME}"
export WRFSCRIPT="run_cycling_WRF.pbs" # WRF suffix assumed
export WPSSCRIPT="run_cycling_WPS.pbs" # WRF suffix assumed, WPS suffix substituted: ${JOBNAME%_WRF}_WPS
export ARSCRIPT="" # archive script to be executed after WRF finishes
export ARINTERVAL="" # default: every time
export WAITFORWPS='NO' # stay on compute node until WPS for next step finished, in order to submit next WRF job
# run configuration
export NODES=${PBS_NUM_NODES} # set in PBS section
export TASKS=16 # number of MPI task per node (Hpyerthreading!)
export THREADS=1 # number of OpenMP threads
# directory setup
export INIDIR="${PBS_O_WORKDIR}" # experiment root (launch directory)
export RUNNAME="${CURRENTSTEP}" # step name, not job name!
export WORKDIR="${INIDIR}/${RUNNAME}/" # step folder
export SCRIPTDIR="${INIDIR}/scripts/" # location of component scripts (pre/post processing etc.)
export BINDIR="${INIDIR}/bin/" # location of executables (WRF and WPS)
# N.B.: use absolute path for script and bin folders

echo
module list
echo


###                                                                    ##
###   ***   Below this line nothing should be machine-specific   ***   ##
###                                                                    ##


# launch feedback
echo
hostname
uname
echo
echo "   ***   ${JOBNAME}   ***   "
echo


## real.exe settings
export RUNREAL=0 # don't run real.exe again (requires metgrid.exe output)
# optional arguments: $RUNREAL, $RAMIN, $RAMOUT
# folders: $REALIN, $REALOUT
# N.B.: RAMIN/OUT only works within a single node!

## WRF settings
# optional arguments: $RUNWRF, $GHG ($RAD, $LSM)
export GHG='' # GHG emission scenario
export RAD='' # radiation scheme
export LSM='' # land surface scheme
# folders: $WRFIN, $WRFOUT, $TABLES
export REALOUT="${WORKDIR}" # this should be default anyway
export WRFIN="${WORKDIR}" # same as $REALOUT
export WRFOUT="${INIDIR}/wrfout/" # output directory
export RSTDIR="${WRFOUT}"

## setup job environment
cd "${INIDIR}"
source "${SCRIPTDIR}/setup_WRF.sh" # load machine-specific stuff

## run WPS/pre-processing for next step
# read next step from stepfile
NEXTSTEP=$(python "${SCRIPTDIR}/cycling.py" "${CURRENTSTEP}")

# launch pre-processing for next step
eval "${SCRIPTDIR}/launchPreP.sh" # primarily for WPS and real.exe


## run WRF for this step
# N.B.: work in existing work dir, created by caller instance;
# i.e. don't remove namelist files in working directory!

# start timing
echo
echo "   ***   Launching WRF for current step: ${CURRENTSTEP}   ***   "
date
echo

# run script
eval "${SCRIPTDIR}/execWRF.sh"
ERR=$? # capture exit code
# mock restart files for testing (correct linking)
#if [[ -n "${NEXTSTEP}" ]]; then
#	touch "${WORKDIR}/wrfrst_d01_${NEXTSTEP}_00"
#	touch "${WORKDIR}/wrfrst_d01_${NEXTSTEP}_01"
#fi

if [[ $ERR != 0 ]]; then
  # end timing
  echo
  echo "   ###   WARNING: WRF step ${CURRENTSTEP} failed   ###   "
  date
  echo
  exit ${ERR}
fi # if error

# end timing
echo
echo "   ***   WRF step ${CURRENTSTEP} completed   ***   "
date
echo


## launch post-processing
eval "${SCRIPTDIR}/launchPostP.sh" # mainly archiving, but may include actual post-processing


## resubmit job for next step
eval "${SCRIPTDIR}/resubJob.sh" # requires submission command from setup script


# copy driver script into work dir to signal completion
cp "${INIDIR}/${WRFSCRIPT}" "${WORKDIR}"
